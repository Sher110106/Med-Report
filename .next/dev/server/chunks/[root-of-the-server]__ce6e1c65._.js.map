{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 46, "column": 0}, "map": {"version":3,"sources":["file:///Users/sher/project/Med/lib/gemini.ts"],"sourcesContent":["import { GoogleGenerativeAI } from \"@google/generative-ai\";\n\nconst genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);\n\nexport const geminiModels = {\n  pro: genAI.getGenerativeModel({ model: \"gemini-3-pro-preview\" }),\n  flash: genAI.getGenerativeModel({ model: \"gemini-3-flash-preview\" }),\n};\n\nexport async function callGeminiWithImage(\n  model: \"pro\" | \"flash\",\n  prompt: string,\n  imageBase64: string,\n  mimeType: string\n) {\n  const selectedModel = geminiModels[model];\n\n  const imagePart = {\n    inlineData: {\n      data: imageBase64,\n      mimeType,\n    },\n  };\n\n  const result = await selectedModel.generateContent([prompt, imagePart]);\n  const response = await result.response;\n  return response.text();\n}\n\nexport async function callGeminiWithText(\n  model: \"pro\" | \"flash\",\n  prompt: string,\n  text: string\n) {\n  const selectedModel = geminiModels[model];\n  const fullPrompt = `${prompt}\\n\\nINPUT TEXT:\\n\"\"\"\\n${text}\\n\"\"\"`;\n\n  const result = await selectedModel.generateContent(fullPrompt);\n  const response = await result.response;\n  return response.text();\n}\n"],"names":[],"mappings":";;;;;;;;AAAA;;AAEA,MAAM,QAAQ,IAAI,wMAAkB,CAAC,QAAQ,GAAG,CAAC,cAAc;AAExD,MAAM,eAAe;IAC1B,KAAK,MAAM,kBAAkB,CAAC;QAAE,OAAO;IAAuB;IAC9D,OAAO,MAAM,kBAAkB,CAAC;QAAE,OAAO;IAAyB;AACpE;AAEO,eAAe,oBACpB,KAAsB,EACtB,MAAc,EACd,WAAmB,EACnB,QAAgB;IAEhB,MAAM,gBAAgB,YAAY,CAAC,MAAM;IAEzC,MAAM,YAAY;QAChB,YAAY;YACV,MAAM;YACN;QACF;IACF;IAEA,MAAM,SAAS,MAAM,cAAc,eAAe,CAAC;QAAC;QAAQ;KAAU;IACtE,MAAM,WAAW,MAAM,OAAO,QAAQ;IACtC,OAAO,SAAS,IAAI;AACtB;AAEO,eAAe,mBACpB,KAAsB,EACtB,MAAc,EACd,IAAY;IAEZ,MAAM,gBAAgB,YAAY,CAAC,MAAM;IACzC,MAAM,aAAa,GAAG,OAAO,sBAAsB,EAAE,KAAK,KAAK,CAAC;IAEhE,MAAM,SAAS,MAAM,cAAc,eAAe,CAAC;IACnD,MAAM,WAAW,MAAM,OAAO,QAAQ;IACtC,OAAO,SAAS,IAAI;AACtB"}},
    {"offset": {"line": 91, "column": 0}, "map": {"version":3,"sources":["file:///Users/sher/project/Med/lib/prompts.ts"],"sourcesContent":["export const OCR_EXTRACTION_PROMPT = `### SYSTEM ROLE\nYou are an expert OCR (Optical Character Recognition) specialist focused on medical documents.\n\n### INSTRUCTION\nYour ONLY task is to transcribe the handwritten text from the medical note image exactly as it appears.\n\n**Critical Rules:**\n1. **NO CORRECTIONS**: Do not fix spelling, grammar, or medical terminology errors\n2. **NO INTERPRETATION**: Do not try to make sense of ambiguous text\n3. **PRESERVE LAYOUT**: Maintain line breaks and spacing where possible\n4. **CHARACTER-BY-CHARACTER**: If \"l0mg\" is written (with lowercase 'L'), write \"l0mg\" (don't correct to \"10mg\")\n5. **UNCERTAIN TEXT**: If a word is completely illegible, write [ILLEGIBLE] in its place\n6. **NO ASSUMPTIONS**: If you see \"BP: 12O/8O\" (with letter O), write exactly that\n\n### OUTPUT FORMAT\nProvide ONLY the raw transcribed text with no additional commentary, explanations, or JSON formatting.\n\nStart the transcription on the next line:\n---\n`;\n\nexport const SOAP_EXTRACTION_PROMPT = `### SYSTEM ROLE\nYou are an expert Medical Scribe and Clinical Data Validator. You are processing a raw image of a handwritten doctor's note.\n\n### INSTRUCTION\nYour task is to execute a 2-Stage extraction process to convert the handwritten image into a structured SOAP JSON format.\n\n**STAGE 1: OCR CORRECTION & CONTEXTUALIZATION (Mental Scratchpad)**\n* First, internally transcribe the handwritten text.\n* Apply \"Contextual Correction\": If a word is ambiguous (e.g., \"l\" vs \"1\"), use the medical context to correct it (e.g., if near \"BP\", \"120/80\" is likely; if near \"mg\", \"1\" is likely).\n* **Do not output the raw transcript.** Use it only to populate the JSON in Stage 2.\n\n**STAGE 2: SOAP STRUCTURED EXTRACTION**\nMap the transcribed information into the following JSON Schema. Follow these specific constraints based on the \"Spiral Prompting\" methodology:\n1. **Missing Data:** If a field (e.g., \"Allergies\") is not found in the text, return \"null\" or \"Unknown\". Do not hallucinate.\n2. **Certainty Degree (CD):** For the \"Assessment\" (Diagnosis) and \"Plan\" (Rx), you must provide a confidence score (0.00 to 1.00) indicating how legible the handwriting was for that specific item.\n3. **Evidence:** For every Diagnosis, quote the specific text fragment that supports it.\n\n### TARGET SCHEMA (JSON)\nOutput ONLY this JSON object. Do not include markdown formatting or conversational text.\n\n{\n  \"soap_note\": {\n    \"subjective\": {\n      \"chief_complaint\": \"<Primary reason for visit>\",\n      \"hpi\": \"<History of Present Illness - narrative>\",\n      \"symptoms\": [\"<List of reported symptoms>\"],\n      \"patient_history\": \"<Relevant past medical history or Unknown>\"\n    },\n    \"objective\": {\n      \"vitals\": {\n        \"bp\": \"<Blood Pressure or null>\",\n        \"hr\": \"<Heart Rate or null>\",\n        \"temp\": \"<Temperature or null>\",\n        \"rr\": \"<Respiratory Rate or null>\",\n        \"weight\": \"<Weight or null>\"\n      },\n      \"physical_exam\": {\n        \"findings\": [\"<List distinct physical exam observations>\"],\n        \"text_raw\": \"<Full text of exam section>\"\n      },\n      \"labs_imaging\": \"<Any results mentioned or Pending>\"\n    },\n    \"assessment\": {\n      \"primary_diagnosis\": {\n        \"value\": \"<The main diagnosis>\",\n        \"certainty_degree\": 0.00,\n        \"evidence_text\": \"<Exact handwritten text snippet used>\"\n      },\n      \"differential_diagnosis\": [\"<List of other potential diagnoses>\"]\n    },\n    \"plan\": {\n      \"medications\": [\n        {\n          \"drug\": \"<Name>\",\n          \"dosage\": \"<Strength e.g. 500mg>\",\n          \"sig\": \"<Instructions e.g. BID x 7 days>\",\n          \"handwriting_confidence\": 0.00\n        }\n      ],\n      \"procedures_ordered\": [\"<List of labs/referrals>\"],\n      \"patient_instructions\": \"<Advice given to patient>\"\n    }\n  },\n  \"metadata\": {\n    \"ocr_quality_check\": \"<Comment on overall legibility>\",\n    \"critical_ambiguities\": \"<List any text that was too messy to read safely>\"\n  }\n}`;\n\nexport const SOAP_FROM_TEXT_PROMPT = `### SYSTEM ROLE\nYou are an expert Clinical Data Structuring Specialist. Your task is to parse raw, noisy OCR text from a general doctor's note and extract structured data into a precise JSON format.\n\n### INSTRUCTIONS\nBased on the clinical text provided in the \"INPUT\" section, extract the value, evidence, and certainty degree (CD: 0.00 to 1.00) for the attributes listed in the Schema below.\n\n**1. OCR Correction & Inference:** The input is raw OCR text and may contain typos (e.g., \"10mg\" read as \"l0mg\"). You must infer the correct medical terms based on context. If a term is ambiguous, lower the Certainty Degree (CD).\n\n**2. SOAP Structure:**\nExtract the following fields. If a field is not mentioned, return \"Unknown\" or null.\n\n**3. Output Requirements (Spiral Logic):**\nFor diagnosis and medications, you must provide:\n- \\`value\\`: The cleaned, standardized value\n- \\`certainty_degree\\`: A float between 0.00 and 1.00 indicating certainty\n- \\`evidence_text\\`: The exact substring from the OCR text used as basis\n\n**4. Handling Negation & Nuance:**\n- Ensure valid inference. Do not extract \"Diabetes\" as a diagnosis if the text says \"No history of Diabetes.\"\n- If evidence is not explicitly present, return value as \"Unknown\".\n\n**5. Final Output:**\nOutput ONLY the valid JSON object following this exact schema:\n\n{\n  \"soap_note\": {\n    \"subjective\": {\n      \"chief_complaint\": \"<Primary reason for visit>\",\n      \"hpi\": \"<History of Present Illness - narrative>\",\n      \"symptoms\": [\"<List of reported symptoms>\"],\n      \"patient_history\": \"<Relevant past medical history or Unknown>\"\n    },\n    \"objective\": {\n      \"vitals\": {\n        \"bp\": \"<Blood Pressure or null>\",\n        \"hr\": \"<Heart Rate or null>\",\n        \"temp\": \"<Temperature or null>\",\n        \"rr\": \"<Respiratory Rate or null>\",\n        \"weight\": \"<Weight or null>\"\n      },\n      \"physical_exam\": {\n        \"findings\": [\"<List distinct physical exam observations>\"],\n        \"text_raw\": \"<Full text of exam section>\"\n      },\n      \"labs_imaging\": \"<Any results mentioned or Pending>\"\n    },\n    \"assessment\": {\n      \"primary_diagnosis\": {\n        \"value\": \"<The main diagnosis>\",\n        \"certainty_degree\": 0.00,\n        \"evidence_text\": \"<Exact text snippet used>\"\n      },\n      \"differential_diagnosis\": [\"<List of other potential diagnoses>\"]\n    },\n    \"plan\": {\n      \"medications\": [\n        {\n          \"drug\": \"<Name>\",\n          \"dosage\": \"<Strength e.g. 500mg>\",\n          \"sig\": \"<Instructions e.g. BID x 7 days>\",\n          \"handwriting_confidence\": 0.00\n        }\n      ],\n      \"procedures_ordered\": [\"<List of labs/referrals>\"],\n      \"patient_instructions\": \"<Advice given to patient>\"\n    }\n  },\n  \"metadata\": {\n    \"ocr_quality_check\": \"<Comment on overall legibility>\",\n    \"critical_ambiguities\": \"<List any text that was too messy to read safely>\"\n  }\n}`;\n\nexport const LABS_EXTRACTION_PROMPT = `### ROLE\nYou are an expert Clinical Data Structuring Specialist. Your task is to parse raw, noisy OCR text from a doctor's note and extract structured data into a precise JSON format.\n\n### INSTRUCTIONS\nBased on the clinical text provided in the \"INPUT\" section, extract the value, evidence, and certainty degree (CD) for the attributes listed below.\n\n**CRITICAL RULE: MISSING NO DATA**\nYou must capture ALL quantifiable test results (Bloodwork, Urine, Imaging). Do not summarize them; extract them individually.\n\n**1. OCR Correction & Inference:**\nThe input is raw OCR text. Correct obvious typos (e.g., \"S6PT\" -> \"SGPT\", \"1O0 mg\" -> \"100 mg\") based on medical context.\n\n**2. Target Schema (JSON Structure):**\n\nA. **patient_metadata**:\n   - name, age, gender, date_of_visit (YYYY-MM-DD).\n\nB. **diagnostics_and_labs** (CRITICAL SECTION):\n   - Extract every single lab test or diagnostic measure found (e.g., SGPT, Hgb, TSH, X-Ray findings).\n   - For each item, create an object with:\n     - test_name: Standardized name (e.g., \"ALT/SGPT\").\n     - value: The numeric or qualitative result (e.g., \"45\", \"Negative\").\n     - unit: The unit of measurement (e.g., \"IU/L\", \"mg/dL\"). If missing, output \"Unknown\".\n     - flag: Any indicator of abnormality (e.g., \"High\", \"Low\", \"Critical\", or \"Normal\").\n     - original_text: The exact text snippet from the OCR.\n\nC. **clinical_assessment**:\n   - chief_complaint: Reason for visit.\n   - symptoms: List of subjective symptoms reported.\n   - diagnosis: Confirmed or suspected conditions.\n\nD. **treatment_plan**:\n   - medications: List of drugs (Name, Dosage, Frequency).\n   - procedures_ordered: Specific tests or procedures ordered for the future.\n   - lifestyle_advice: Diet/exercise instructions.\n\n**3. Output Requirements:**\nFor diagnostics_and_labs and medications, return a LIST of objects.\nFor all extracted values, include a confidence_score (0.00-1.00).\n\nOutput ONLY the valid JSON object following this schema:\n{\n  \"patient_metadata\": {\n    \"name\": \"<Patient name or Unknown>\",\n    \"age\": \"<Age or Unknown>\",\n    \"gender\": \"<Gender or Unknown>\",\n    \"date_of_visit\": \"<YYYY-MM-DD or Unknown>\"\n  },\n  \"diagnostics_and_labs\": [\n    {\n      \"test_name\": \"<Standardized test name>\",\n      \"value\": \"<Result value>\",\n      \"unit\": \"<Unit or Unknown>\",\n      \"flag\": \"<High/Low/Critical/Normal>\",\n      \"original_text\": \"<Exact OCR snippet>\",\n      \"confidence_score\": 0.00\n    }\n  ],\n  \"clinical_assessment\": {\n    \"chief_complaint\": \"<Reason for visit>\",\n    \"symptoms\": [\"<List of symptoms>\"],\n    \"diagnosis\": \"<Diagnosis or Unknown>\"\n  },\n  \"treatment_plan\": {\n    \"medications\": [\n      {\n        \"name\": \"<Drug name>\",\n        \"dosage\": \"<Dosage>\",\n        \"frequency\": \"<Frequency>\",\n        \"confidence_score\": 0.00\n      }\n    ],\n    \"procedures_ordered\": [\"<List of procedures/tests ordered>\"],\n    \"lifestyle_advice\": \"<Diet/exercise instructions or Unknown>\"\n  },\n  \"metadata\": {\n    \"ocr_quality_check\": \"<Comment on overall legibility>\",\n    \"extraction_notes\": \"<Any important notes about the extraction>\"\n  }\n}`;\n"],"names":[],"mappings":";;;;;;;;;;AAAO,MAAM,wBAAwB,CAAC;;;;;;;;;;;;;;;;;;;AAmBtC,CAAC;AAEM,MAAM,yBAAyB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CAmEtC,CAAC;AAEK,MAAM,wBAAwB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CAuErC,CAAC;AAEK,MAAM,yBAAyB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CA+EtC,CAAC"}},
    {"offset": {"line": 345, "column": 0}, "map": {"version":3,"sources":["file:///Users/sher/project/Med/app/api/extract-ocr/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from \"next/server\";\nimport { callGeminiWithImage } from \"@/lib/gemini\";\nimport { OCR_EXTRACTION_PROMPT } from \"@/lib/prompts\";\n\nexport async function POST(request: NextRequest) {\n  try {\n    const formData = await request.formData();\n    const image = formData.get(\"image\") as File;\n\n    if (!image) {\n      return NextResponse.json(\n        { success: false, error: \"No image provided\" },\n        { status: 400 }\n      );\n    }\n\n    const bytes = await image.arrayBuffer();\n    const buffer = Buffer.from(bytes);\n    const base64Image = buffer.toString(\"base64\");\n\n    const rawText = await callGeminiWithImage(\n      \"flash\",\n      OCR_EXTRACTION_PROMPT,\n      base64Image,\n      image.type\n    );\n\n    const cleanedText = rawText\n      .replace(/^---\\n/, \"\")\n      .replace(/\\n---$/, \"\")\n      .trim();\n\n    return NextResponse.json({\n      success: true,\n      rawText: cleanedText,\n    });\n  } catch (error: any) {\n    console.error(\"OCR extraction error:\", error);\n    return NextResponse.json(\n      {\n        success: false,\n        error: error.message || \"OCR processing failed\",\n      },\n      { status: 500 }\n    );\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAEO,eAAe,KAAK,OAAoB;IAC7C,IAAI;QACF,MAAM,WAAW,MAAM,QAAQ,QAAQ;QACvC,MAAM,QAAQ,SAAS,GAAG,CAAC;QAE3B,IAAI,CAAC,OAAO;YACV,OAAO,kKAAY,CAAC,IAAI,CACtB;gBAAE,SAAS;gBAAO,OAAO;YAAoB,GAC7C;gBAAE,QAAQ;YAAI;QAElB;QAEA,MAAM,QAAQ,MAAM,MAAM,WAAW;QACrC,MAAM,SAAS,OAAO,IAAI,CAAC;QAC3B,MAAM,cAAc,OAAO,QAAQ,CAAC;QAEpC,MAAM,UAAU,MAAM,IAAA,wJAAmB,EACvC,SACA,2JAAqB,EACrB,aACA,MAAM,IAAI;QAGZ,MAAM,cAAc,QACjB,OAAO,CAAC,UAAU,IAClB,OAAO,CAAC,UAAU,IAClB,IAAI;QAEP,OAAO,kKAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,SAAS;QACX;IACF,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,yBAAyB;QACvC,OAAO,kKAAY,CAAC,IAAI,CACtB;YACE,SAAS;YACT,OAAO,MAAM,OAAO,IAAI;QAC1B,GACA;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}